\documentclass[licencjacka]{pracamgr_Kogni}
\usepackage{enumitem}
\usepackage{setspace}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{tikz-dependency}
\usepackage{gb4e}
\usepackage{hyperref}
 \hypersetup{
     colorlinks=true,
     linkcolor=black,
     citecolor=black,
     urlcolor=darkgray,
     }
\onehalfspacing
\autor{Kamil Tomaszek}{432044}
\title{Minimalizacja długości zależności w~strukturach współrzędnie złożonych: badanie korpusowe na~podstawie Polish Dependency Bank}
\kierunek{kognitywistyka}
\opiekun{\\
\bfseries prof. dr~hab. Adama Przepiórkowskiego\\
Uniwersytet Warszawski}
\date{czerwiec 2023}
\keywords{koordynacja, minimalizacja długości zależności, Polish Dependency Bank, drzewa zależnościowe, korpusy językowe}

\begin{document}

\maketitle

\tytulang{Dependency Length Minimization in~coordinate structures: A~corpus study based on~Polish Dependency Bank}

\begin{abstract}
Praca licencjacka na~temat „Minimalizacja długości zależności w~strukturach współrzędnie złożonych: badanie korpusowe na~podstawie Polish Dependency Bank” jest poświęcona zjawisku minimalizacji długości zależności w~koordynacji w~języku polskim. Celem pracy jest sprawdzenie hipotez na~ten temat oraz przedstawienie dodatkowych analiz. Ma~ona charakter empiryczny i~opiera się na~danych pochodzących z~korpusu Polish Dependency Bank. 


%DO POPRAWIENIA
%Praca składa się z~sześciu rozdziałów. W~pierwszym rozdziale przedstawiłem motywację, cel i~zakres pracy oraz jej strukturę. W~drugim rozdziale omówiłem teoretyczne podstawy pracy, tj. reprezentacje koordynacji w~języku polskim, teorię zależności składniowej i~DLM w~koordynacji. W~trzecim rozdziale opisałem źródło danych i~narzędzia do~analizy, tj. PDB i~preprocessing danych za~pomocą algorytmu napisanego w~Pythonie. W~czwartym rozdziale zaprezentowałem wyniki analizy statystycznej wykonanej w~R~oraz testowanie hipotez za~pomocą m. in. testu chi-kwadrat. W~piątym rozdziale dokonałem dyskusji wyników, interpretacji ich znaczenia i~porównania z~literaturą naukową. W~szóstym rozdziale podsumowałem pracę i~wnioski oraz zaproponowałem perspektywy dalszych badań.
\end{abstract}

\thispagestyle{empty}
\setcounter{page}{3}
\tableofcontents

\chapter{Wstęp}
W~tym rozdziale przedstawiam motywację i~cel niniejszej pracy licencjackiej, a~także omawiam jej zakres oraz strukturę.

\section{Motywacja i~cel pracy}

W pracy tej analizuję zjawisko minimalizacji długości zależności -- DLM (ang. \textit{Dependency Length Minimization}), czyli tendencji do~umieszczania elementów wypowiedzi o~różnych długościach w~sposób, by~zmniejszyć odległość zarówno między nimi samymi, jak i~między nimi a~innymi elementami zdania, w~koordynacjach w~języku polskim. Koordynacja to
%naprawić!Nie jakie są rozdziały, tylko co się dzieje!
% zjawisko, gdy wiele części zdania ma~jeden nadrzędnik i~każda z~nich się z~nim koordynuje. Zjawisko to~jest istotne dla teorii składniowej i~reprezentacji językowych, ponieważ dotyczy zarówno formy jak i~znaczenia zdań. W~pracy sprawdzam dwie hipotezy dotyczące długości członów w~koordynacjach w~języku polskim: 1. że~dłuższy człon koordynacji jest częściej ze~strony prawej i~2. że~pozycja nadrzędnika wpływa na rozkład długości członów koordynacji.
%napraw poniższą komendę:
\begin{exe}
    \ex
    \textit{Widziałem} [Asię \textbf{i} jej śmiesznego, młodszego brata]. 
    \label {ex:1}
\end{exe}
Długości członów mierzę na~cztery różne sposoby, licząc znaki, sylaby, słowa oraz tokeny\footnote{tokeny -- zalicza się do nich całe słowa (np. 'być', 'kolor'), części słów (m. in. wyrazy po oderwaniu końcówek fleksyjnych oraz same końcówki, (np. 'zrobił', 'em')), a także interpunkcję (np. ',', '-', '?')}. W~przykładzie (\ref{ex:1}) odpowiednie wartości wynosiłyby (4~vs.~31, 2~vs.~9, 1~vs.~4, 1~vs.~5). Szybko pokazuję, że~pierwsza z~hipotez zachodzi w~większości przypadków, więc następnie omawiam wpływ obecności i~pozycji nadrzędnika oraz długości różnicy między analizowanymi członami na~proporcje danych, w~których hipoteza ta~jest prawdziwa. Praca ta~ma~charakter empiryczny, opiera się na~danych pochodzących z~Polish Dependency Bank (PDB), czyli korpusu języka polskiego zawierającego ponad 22 tysiące drzew zależnościowych oraz na~wcześniejszej pracy badającej te~same zależności, ale dla języka angielskiego \citep{Przepiorkowski2023}.

\section{Zakres i~struktura pracy}
Praca składa się z~sześciu rozdziałów. W~rozdziale drugim omawiam teoretyczne podstawy pracy, tj. przedstawiam czym są~koordynacje -- na~przykładzie języka polskiego, prezentuję zarys teorii zależności składniowej, opisuję teorię minimalizacji zależności oraz wskazuję różne reprezentacje zależnościowe wraz z~ich przewidywaniami. W~rozdziale trzecim opisuję źródło danych, czyli Polish Dependency Bank, jak i~ich preprocessing -- działanie algorytmu, napisanego w~języku Python, wybierającego koordynacje oraz informacje o~nich z~PDB, a~także pokazuję format danych po~preprocessingu. W~rozdziale czwartym prezentuję hipotezy badawcze, ich testowanie wraz z~analizami statystycznymi w~języku R. W~rozdziale piątym omawiam wyniki badań i~ich interpretację w~kontekście istniejącej wcześniej literatury naukowej. W~rozdziale szóstym podsumowuję pracę, wyciągam z~niej wnioski oraz proponuję perspektywy dalszych badań.

\chapter{Podstawy teoretyczne}
W~tym rozdziale omawiam teoretyczne podstawy pracy, tj. opisuję czym są~koordynacje, przedstawiam zarys teorii zależności składniowej, prezentuję minimalizację teorii zależności oraz wskazuję różne reprezentacje zależnościowe wraz z~ich przewidywaniami.

\section{Koordynacja w~języku polskim}
Zacznę od~przedstawienia pojęcia koordynacji. Koordynacja to %naprawić! zjawisko w~językach naturalnych, które zachodzi w~struktruach złożonych -- zarówno współrzędnie, NIEPRAWDA! jak i~podrzędnie. Polega na~zestawieniu dwóch lub więcej elementów o~tej samej funkcji składniowej za~pomocą spójników lub interpunkcji i~tym samym złączenie ich w~jeden, większy element, zachowujący te~same funkcje składniowe. Jest ono jednym z~podstawowych sposobów łączenia słów, czy zdań. 
Elementami koordynacji mogą być zarówno pojedyncze słowa \ref{ex:2a}, frazy \ref{ex:2b}, jak i~całe zdania \ref{ex:2c}:
\begin{exe}
    \ex
    \setlist[enumerate]{label=\alph{enumi}., ref=(2\alph{enumi})}
    \begin{enumerate}
        \item {[Ania \textbf{i} Julia] \textit{idą} na~spacer.}
            \label {ex:2a}
        \item {[Wesoła Marysia \textbf{oraz} smutny Janek] \textit{wybrali się} do~parku.}
            \label {ex:2b}
        \item {\textit{Kuba} zjadł obiad \textbf{a} Marysia poszła spać.}
            \label {ex:2c}
    \end{enumerate}
    \label{ex:2}
\end{exe}
Człony koordynacji nazywamy koniunktami, to~co~je~łączy -- spójnikiem współrzędnym (w~przykładach w~tej pracy jest on~ilustrowany pogrubionym tekstem), a~wyraz nadrzędny względem obu członów -- nadrzędnikiem koordynacji (w~przykładach ilustrowany kursywą). Jak widać w~\ref{ex:2c} nie zawsze istnieje nadrzędnik koordynacji.
W~podanych wyżej przykładach koniunktami są: \ref{ex:2a} -- Ania, Julia; \ref{ex:2b} -- Wesoła Marysia, smutny Janek; \ref{ex:2c} -- zjadł obiad, poszła spać.

Ze~względów semantycznych zwykle wyróżnia się cztery rodzaje koordynacji: koordynacje koniunkcyjne \ref{ex:3a}, koordynacje dysjunkcyjne \ref{ex:3b}, koordynacje adwersatywne \ref{ex:3c} oraz koordynacje kauzalne \ref{ex:3d} \citep{Haspelmath2007}. Każde z~nich używają różnych zestawów spójników, które łączą koniunkty. W~koordynacjach koniunkcyjnych człony łączą m. in. spójniki \textit{i}, \textit{oraz}, \textit{ani}, \textit{tudzież}, \textit{również}, a~w~koordynacjach dysjunkcyjnych -- \textit{albo}, \textit{bądź}, \textit{lub}, \textit{czy}, lecz w~obu tych kategoriach wykorzystywana jest także interpunkcja. W~koordynacjach adwersatywnych używamy m. in. spójników \textit{ale}, \textit{lecz}, \textit{zaś}, \textit{natomiast}, \textit{jednak}, a~w~koordynacjach kauzalnych -- \textit{bo}, \textit{bowiem}. %W~tej pracy skupię się na~pierwszych trzech rodzajach koordynacji, BO W PDB(?) jako że~to~one występują w~strukturach współrzędnie złożonych. (zob. §3.1)
\begin{exe}
    \ex
    \setlist[enumerate]{label=\alph{enumi}., ref=(3\alph{enumi})}
    \begin{enumerate}
        \item {Marta \textit{zjadła} [jabłko \textbf{i} gruszkę].}
            \label {ex:3a}
        \item {Ona miała [szesnaście \textbf{lub} siedemnaście] \textit{lat}.}
            \label {ex:3b}
        \item {\textit{Byli} [ładni, \textbf{ale} głupi].}
            \label {ex:3c}
        \item {[Nie zrobiłem pracy domowej, \textbf{bo} nie chciałem].}
            \label {ex:3d}
    \end{enumerate}
    \label{ex:3}
\end{exe}
\section{Zarys teorii zależności składniowej}
%Teoria zależności składniowej jest jednym z~głównych podejść do~analizy struktury zdania w~lingwistyce. Teoria ta~zakłada, że~każde zdanie składa się z~korzenia (root) i~zależnych od~niego elementów, które są~połączone za~pomocą krawędzi drzewa składniowego.\\
%Teoria ta~opiera się na~kilku podstawowych założeniach \citep{Liu2008}:\\
%- Struktura zdania wynika z~zależności pomiędzy słowami, a~nie z~ich kolejności. W~tym podejściu, zdanie jest analizowane jako złożenie zależności między jego elementami, a~nie jako sekwencja słów, jak w~tradycyjnym podejściu gramatycznym.\\
%- Każda relacja między elementami jest relacją między dokładnie dwoma elementami\\
%- Zazwyczaj relacje zależności są~asymetryczne, jednokierunkowe, gdzie jeden z~elementów jest korzeniem (lokalnym), a~drugi elementem od~niego zależnym.\\
%- Korzeń zdania jest najważniejszym elementem, który określa jego znaczenie i~funkcję komunikacyjną. \\
%- Zależności są~oznaczane etykietami, które określają funkcje syntaktyczne elementów zależnych.\\
%- Zmiana kolejności słów w~zdaniu nie wpływa na~jego strukturę zależnościową, a~jedynie na~jego znaczenie pragmatyczne lub stylistyczne.


%Mężczyzna z~ciemnymi włosami i~wąsami opiera się o~słup stojąc w~pobliżu innych ludzi.
%Powyższe drzewo należy odczytywać w~konkretny sposób. Elementy, które są~niżej są~zależne od~elementów znajdujących się wyżej, z~którymi są~połączone. Korzeń znajduje się na~samej górze. Tekst pod etykietami słów oznacza: niebieski -- funkcje, które pełnią w~zdaniu oraz zielony -- tzw. \textit{tagi} danych wyrazów. W~tym przypadku, słowo \textbf{opiera} jest korzeniem zdania.

\begin{exe}
    \ex
    \begin{dependency}[theme=simple, edge style = lightgray]
        \begin{deptext}
            Mężczyzna\&z \& ciemnymi \& włosami \& i~\& wąsami \& opiera \& się \& o~\& słup \&, \& stojąc \& w~\& pobliżu \& innych \& ludzi \&. \\
        \end{deptext}
        \deproot{7}{root}
        \depedge{7}{1}{subj}
        \depedge{1}{2}{adjunct}
        \depedge{4}{3}{adjunct}
        \depedge{5}{4}{conjunct}
        \depedge{2}{5}{comp}
        \depedge{5}{6}{conjunct}
        \depedge{7}{8}{refl}
        \depedge{7}{9}{comp}
        \depedge{9}{10}{comp}
        \depedge{12}{11}{punct}
        \depedge{7}{12}{adjunct\_compan}
        \depedge{12}{13}{adjunct\_locat}
        \depedge{13}{14}{mwe}
        \depedge{16}{15}{adjunct}
        \depedge{14}{16}{comp}
        \depedge{7}{17}{punct}
    \end{dependency}
    \label{ex:4}
\end{exe}

Teoria zależności składniowej ma~długą i~bogatą historię, która sięga aż~starożytności. Pierwsze ślady tego podejścia można znaleźć w~gramatyce sanskrytu Pāṇiniego, czy w~pracach wczesnych arabskich gramatyków \citep{Kruijff2002}, a~także w~niektórych teoriach gramatycznych średniowiecza \citep{Covington1984}. W~XX~wieku teoria ta~mocno rozwinęła się zwłaszcza w~lingwistyce klasycznej i~słowiańskiej \citep{Melcuk1988}. \citet{Tesniere1959} podjął próvę stworzenia kompleksowej teorii gramatyki, w~której to~wszystko byłoby oparte na~zależnościach. Przedstawił on~jej potencjał do~uchwycenia podobieństw, jak i~różnic między językami.

Teoria zależności składniowej jest popularnym podejściem w~dziedzinie przetwarzania języka naturalnego, ponieważ umożliwia łatwe i~precyzyjne analizowanie struktury zdania. Ma~ona wiele zastosowań, np. w~dziedzinach takich jak tłumaczenie maszynowe czy analiza sentymentu, ponieważ ułatwia przetwarzanie i~rozumienie znaczenia zdań. W~ostatnich latach powstały projekty takie jak Universal Dependencies (\url{https://universaldependencies.org/}), które mają na~celu zunifikowanie reprezentacji lingwistycznych (w~tym wypadku: morfosyntaktycznej i składniowej) dla różnych języków. Dla języka polskiego stworzono już kilka korpusów zgodnych z tym standardem \citep{Przepiorkowski2020} %zacytowac aline
 oraz cały czas powstają nowe, także w innych językach.

\section{Minimalizacja długości zależności}
Minimalizacja długości zależności (DLM) to~zasada, według której języki naturalne dążą do~zmniejszania odległości między słowami zależnymi syntaktycznie. Zasada ta~jest odnotowywana w~lingwistyce już od~długiego czasu i~pozwala nam na~bardziej efektywne analizowanie i~generowanie języka naturalnego. W~ciągu ostatnich 20 lat hipoteza o~nacisku na~DLM została wykorzystana do~wyjaśnienia wielu z~najbardziej uniwersalnych właściwości języków \citep{FutrellEtAl2015}.
Jak twierdzą \citet{Hawkins1994} i~\citet{FutrellEtAl2020}, rozróżniamy jej występowanie na~poziom gramatyczny, jak i~codzienne użycie języka. \citet{Liu2008} twierdzi, że~długości zależności mogłyby być wskaźnikiem trudności danego języka, sugerując przy tym pewną uniwersalność stosowania DLM w~celu łatwiejszego zrozumienia mowy i~pisma.

Według DLM, jeśli oba ustawienia członów koordynacji binarnych (jeden człon raz z~lewej strony, raz z~prawej) są~gramatycznie poprawne, to~bliżej głowy znajdzie się krótszy człon. W~przykładach (5\ref{ex:5a}--\ref{ex:5b}) oba ustawienia wydają się brzmieć naturalnie, jednak gdy wydłużymy jeden z~członów -- w~(5\ref{ex:5c}--\ref{ex:5d}), zauważymy, że~bardziej naturalne będzie ustawienie krótszego członu z~lewej strony.
\begin{exe}
    \ex
    \setlist[enumerate]{label=\alph{enumi}., ref=\alph{enumi}}
    \begin{enumerate}
        \item {\textit{Nie ma} [Kamila \textbf{i} Julii].
            \label{ex:5a}}
        \item {\textit{Nie ma} [Julii \textbf{i} Kamila].
            \label{ex:5b}}
        \item {\textit{Nie ma} [wiecznie spóźnionej Julii \textbf{i} Kamila].
            \label{ex:5c}}
        \item {\textit{Nie ma} [Kamila \textbf{i} wiecznie spóźnionej Julii].
            \label{ex:5d}}
    \end{enumerate}
    \label{ex:5}
\end{exe}
%NIEPRAWDA!\citet{Hawkins1994} argumentuje, że~DLM występuje w~gramatyce, ale niekoniecznie w~użyciu codziennym. Jako powód wskazuje, że~w~języku angielskim kolejność V-NP-PP\footnote{V -- czasownik (ang. \textit{verb}), NP -- fraza rzeczownikowa (ang. \textit{nomimal phrase}), PP -- fraza przyimkowa (ang. \textit{prepositional phrase})} występuje częsciej niż V-PP-NP nie tylko gdy NP~jest krótsze od~PP, ale i~wtedy gdy są~podobnej długości. Używa on~tego przykładu, ponieważ jest on~jednym z~tych, które uważa się za~ilustrujące występowanie DLM (jako że~NP~są~zazwyczaj krótsze niż PP). Słowa Hawkinsa dla języka angielskiego ilustrują przykłady (6a, 6b), w~których kolejność V-NP-PP jest bardziej naturalna niż V-PP-NP), mimo że~obie frazy są~podobnej długości. Zdanie (6c) również brzmi jednak naturalnie, co~wskazuje na~pewien wpływ dodatkowego czynnika -- długości różnicy obu członów koordynacji na~to, czy DLM będzie w~danym przypadku zachowana.
\newcounter{mpFootnoteValueSaver}
\setcounter{mpFootnoteValueSaver}{\value{footnote}}
\begin{exe}
    \ex
    \setlist[enumerate]{label=\alph{enumi}., ref=\alph{enumi}}
    \begin{enumerate}
        \item 
        \begin{tabular}[t]{l l l l}
                I gave &<a book> &<to John> &.\\
                Dałem\footnotemark &<książkę> &<Johnowi> &.\\
            \end{tabular}
        \item 
            \begin{tabular}[t]{l l l l}
                I gave &<to John> &<a book> &.\\
                Dałem &<Johnowi> &<książkę> &.\\
            \end{tabular}
        \item
            \begin{tabular}[t]{l l p{8.22cm} l}
                I gave &<to John> &<the most interesting book I've read in years> &.\\
                Dałem &<Johnowi> &<najbardziej interesującą książkę, jaką przeczytałem\textsuperscript{\ref{rodzaj}} od lat> &.\\
            \end{tabular}
    \end{enumerate}
    \label{ex:6}
\end{exe}
\stepcounter{mpFootnoteValueSaver}
    \footnotetext[\value{mpFootnoteValueSaver}]{
        \label{rodzaj}Wyrażenia \textit{I gave} oraz \textit{I've read} można przetłumaczyć również jako odpowiednio \textit{dałam} i \textit{przeczytałam}, nie zawierają one informacji o rodzaju; dla uproszczenia wszystkie przykłady tłumaczę używając rodzaju męskiego}
za: \citet{Przepiorkowski2023}
\\
Jednym ze~sposobów na~badanie DLM jest tworzenie sztucznych języków losowych (w~których kolejność słów, czy relacje zależności są~losowo dobierane) oraz porównywanie długości zależności w~tych językach z~długościami zależności w~językach naturalnych. Badania wykazały, że~języki naturalne mają istotnie krótsze długości zależności niż sztucznie wygenerowane wartości dla przykładowych losowych języków \citep{FutrellEtAl2015}, co~sugeruje, że~istnieje uniwersalna tendencja u~ludzi do~wykorzystywania DLM.

DLM jest również powiązana z~innymi właściwościami języków naturalnych, między innymi z~pozycyjnością głowy. Oznacza ona kierunek występowania nadrzędnika frazy względem jej dopełnienia. Badania wykazały, że~istnieje związek między pozycyjnością głowy a~długością zależności, przy czym języki o~pozycyjności głowy na~końcu frazy(zdania?) mają krótszą długość zależności niż języki o~pozycyjności głowy na~początku frazy(zdania?) \citep{FutrellEtAl2015}.
%opisać pozycyjność głowy! head-final i head-initial!

DLM nie jest jednak jedynym czynnikiem kształtującym strukturę syntaktyczną języków naturalnych. Istnieją również inne ograniczenia i~preferencje, takie jak harmonia języka \citep{Jing2022}, czy preferencje semantyczne, które mogą wpływać na~kolejność słów i~długość zależności. Niektóre z~tych czynników mogą być sprzeczne lub komplementarne względem~DLM. Dlatego DLM należy rozumieć jako jeden z~wielu czynników wpływających na~organizację języka naturalnego.

\section{Różne reprezentacje koordynacji}
Jeśli chodzi o~reprezentacje koordynacji w~postaci drzew zależnościowych, to~możemy wyróżnić 4 podstawowe podejścia \citep{Przepiorkowski2023, PopelEtAl2013}:\\
\depstyle{outer bubble}{minimum height=20pt, rounded corners=8pt,
inner sep=4pt}
\depstyle{inner bubble}{minimum height=14pt, rounded corners=5pt,
inner sep=1pt}
\depstyle{nobubble}{color = white}

\textbf{Podejście Londyńskie} -- jak wskazuje \citet{Przepiorkowski2023} podejście to~nazwać możemy londyńskim, w~duchu nazywania podejść od~nazw miast, w~których zostały one opublikowane. W~angielskiej nomenklaturze możemy również znaleźć je~pod nazwą \textit{multi-headed}. Zakłada ono, że~bezpośrednimi nadrzędnikami każdego z~członów koordynacji jest głowa koordynacji, a~ostatni z~nich jest również nadrzędnikiem spójnika koordynacji.

\begin{exe}
    \ex
    \begin{dependency}[theme = simple, group style = outer bubble]
        \centering
        \begin{deptext}[column sep=0.5cm]
            Głowa \& 1.1 \& 1.2 \& 1.3 \&, \& 2.1 \& 2.2 \& 2.3 \& spójnik \& 3.1 \& 3.2 \& 3.3 \&. \\
        \end{deptext}
        \wordgroup{1}{2}{4}{pierwszy}
        \wordgroup[inner bubble]{1}{2}{2}{1.1}
        \wordgroup[inner bubble]{1}{3}{3}{1.2}
        \wordgroup[inner bubble]{1}{4}{4}{1.3}
        \wordgroup[nobubble]{1}{1}{1}{glowa}
        \wordgroup{1}{6}{8}{drugi}
        \wordgroup[inner bubble]{1}{6}{6}{2.1}
        \wordgroup[inner bubble]{1}{7}{7}{2.2}
        \wordgroup[inner bubble]{1}{8}{8}{2.3}
        \wordgroup[nobubble]{1}{9}{9}{spojnik}
        \wordgroup{1}{10}{12}{trzeci}
        \wordgroup[inner bubble]{1}{10}{10}{3.1}
        \wordgroup[inner bubble]{1}{11}{11}{3.2}
        \wordgroup[inner bubble]{1}{12}{12}{3.3}
        \groupedge{glowa}{pierwszy}{}{0}
        \groupedge{glowa}{drugi}{}{0}
        \groupedge{glowa}{trzeci}{}{0}
        \groupedge{trzeci}{spojnik}{}{0}
    \end{dependency}
    \label{ex:multi-headed}
\end{exe}
\textbf{Podejście Stanfordzkie} -- w~angielskiej nomenklaturze określane także mianem \textit{bouquet}. Zakłada ono, że~bezpośrednim nadrzędnikiem pierwszego z~członów koordynacji jest jej głowa, pierwszy człon równocześnie jest nadrzędnikiem pozostałych członów koordynacji, a~ostatni z~członów jest nadrzędnikiem spójnika koordynacji.
\begin{exe}
    \ex
\begin{dependency}[theme = simple, group style = outer bubble]
    \centering
    \begin{deptext}[column sep=0.5cm]
       Głowa \& 1.1 \& 1.2 \& 1.3 \&, \& 2.1 \& 2.2 \& 2.3 \& spójnik \& 3.1 \& 3.2 \& 3.3 \&. \\
    \end{deptext}
    \wordgroup{1}{2}{4}{pierwszy}
    \wordgroup[inner bubble]{1}{2}{2}{1.1}
    \wordgroup[inner bubble]{1}{3}{3}{1.2}
    \wordgroup[inner bubble]{1}{4}{4}{1.3}
    \wordgroup[nobubble]{1}{1}{1}{glowa}
    \wordgroup{1}{6}{8}{drugi}
    \wordgroup[inner bubble]{1}{6}{6}{2.1}
    \wordgroup[inner bubble]{1}{7}{7}{2.2}
    \wordgroup[inner bubble]{1}{8}{8}{2.3}
    \wordgroup[nobubble]{1}{9}{9}{spojnik}
    \wordgroup{1}{10}{12}{trzeci}
    \wordgroup[inner bubble]{1}{10}{10}{3.1}
    \wordgroup[inner bubble]{1}{11}{11}{3.2}
    \wordgroup[inner bubble]{1}{12}{12}{3.3}
    \groupedge{glowa}{pierwszy}{}{0}
    \groupedge{pierwszy}{drugi}{}{0}
    \groupedge{pierwszy}{trzeci}{}{0}
    \groupedge{trzeci}{spojnik}{}{0}
    \end{dependency}
    \label{ex:stanford}
\end{exe}
\textbf{Podejście Moskiewskie} -- w~angielskiej nomenklaturze spotkać się możemy również z~określeniem \textit{chain}. Zakłada ono, że~każda struktura (tj. człony, głowa oraz spójnik) wewnątrz koordynacji jest bezpośrednim nadrzędnikiem następnej struktury wewnątrz koordynacji.
\begin{exe}
    \ex
    \begin{dependency}[theme = simple, group style = outer bubble]
        \centering
        \begin{deptext}[column sep=0.5cm]
            Głowa \& 1.1 \& 1.2 \& 1.3 \&, \& 2.1 \& 2.2 \& 2.3 \& spójnik \& 3.1 \& 3.2 \& 3.3 \&. \\
        \end{deptext}
        \wordgroup{1}{2}{4}{pierwszy}
        \wordgroup[inner bubble]{1}{2}{2}{1.1}
        \wordgroup[inner bubble]{1}{3}{3}{1.2}
        \wordgroup[inner bubble]{1}{4}{4}{1.3}
        \wordgroup[nobubble]{1}{1}{1}{glowa}
        \wordgroup{1}{6}{8}{drugi}
        \wordgroup[inner bubble]{1}{6}{6}{2.1}
        \wordgroup[inner bubble]{1}{7}{7}{2.2}
        \wordgroup[inner bubble]{1}{8}{8}{2.3}
        \wordgroup[nobubble]{1}{9}{9}{spojnik}
        \wordgroup{1}{10}{12}{trzeci}
        \wordgroup[inner bubble]{1}{10}{10}{3.1}
        \wordgroup[inner bubble]{1}{11}{11}{3.2}
        \wordgroup[inner bubble]{1}{12}{12}{3.3}
        \groupedge{glowa}{pierwszy}{}{0}
        \groupedge{pierwszy}{drugi}{}{0}
        \groupedge{drugi}{spojnik}{}{0}
        \groupedge{spojnik}{trzeci}{}{0}
    \end{dependency}
    \label{ex:chain}
\end{exe}
\textbf{Podejście Praskie} -- w~angielskiej nomenklaturze znane również jako \textit{conjunction-headed}. Zakłada, że~głowa koordynacji jest nadrzędnikiem spójnika koordynacji, który to~jest nadrzędnikiem każdego z~jej członów. To~właśnie to~podejście wykorzystywane jest w~PDB.
\begin{exe}
    \ex 
    \begin{dependency}[theme = simple, group style = outer bubble]
        \centering
        \begin{deptext}[column sep=0.5cm]
        Głowa \& 1.1 \& 1.2 \& 1.3 \&, \& 2.1 \& 2.2 \& 2.3 \& spójnik \& 3.1 \& 3.2 \& 3.3 \&. \\
        \end{deptext}
        \wordgroup{1}{2}{4}{pierwszy}
        \wordgroup[inner bubble]{1}{2}{2}{1.1}
        \wordgroup[inner bubble]{1}{3}{3}{1.2}
        \wordgroup[inner bubble]{1}{4}{4}{1.3}
        \wordgroup[nobubble]{1}{1}{1}{glowa}
        \wordgroup{1}{6}{8}{drugi}
        \wordgroup[inner bubble]{1}{6}{6}{2.1}
        \wordgroup[inner bubble]{1}{7}{7}{2.2}
        \wordgroup[inner bubble]{1}{8}{8}{2.3}
        \wordgroup[nobubble]{1}{9}{9}{spojnik}
        \wordgroup{1}{10}{12}{trzeci}
        \wordgroup[inner bubble]{1}{10}{10}{3.1}
        \wordgroup[inner bubble]{1}{11}{11}{3.2}
        \wordgroup[inner bubble]{1}{12}{12}{3.3}
        \groupedge{glowa}{spojnik}{}{0}
        \groupedge{spojnik}{pierwszy}{}{0}
        \groupedge{spojnik}{drugi}{}{0}
        \groupedge{spojnik}{trzeci}{}{0}
    \end{dependency}
    \label{ex:conjunction-headed}
\end{exe}
Różnice między tymi podejściami możemy badać wraz z~DLM, ponieważ każde z~nich może mieć inne długości zależności dla tego samego zdania. Podejścia zilustrowane przykładami (8, 9) sugerują, że~niezależnie od~tego, czy głowa koordynacji jest z~lewej, czy z~prawej strony, zgodnie z~zasadą DLM pierwszy człon powinien być krótszy -- skróciłoby to~sumę długości wszystkich zależności w~zdaniu. Przy podejściu (10) pozycja głowy koordynacji nie wpływa na~długość zależności, zatem nie ma~żadnych powodów, aby prawy człon stawał się krótszy niż lewy. Zakładając podejście (7) możemy zauważyć, że~pozycja głowy koordynacji z~prawej strony, zgodnie z~DLM może skrócić długości zależności, ustawiając krótszy człon po~spójniku koordynacji, co~byłoby nielogiczne dla pozostałych podejść.
\section{Hipotezy}
\chapter{Dane}
Tekst rozdziału
\section{Polish Dependency Bank}
Tekst sekcji
\section{Preprocessing danych} %w języku python
Tekst sekcji
\section{Dane po~preprocessingu}
Tekst sekcji

\chapter{Analiza statystyczna} %w języku R
Tekst rozdziału
\section{Analiza statystycznaw}
Tekst sekcji
\section{Testowanie hipotez}
Tekst sekcji

\chapter{Dyskusja wyników}
Tekst rozdziału
\section{Podsumowanie wyników badań}
Tekst sekcji
\section{Interpretacja wyników}
Tekst sekcji
\section{Przegląd literatury}
Tekst sekcji

\chapter{Zakończenie}
Tekst rozdziału
\section{Podsumowanie pracy i~wnioski}
Tekst sekcji
\section{Perspektywy dalszych badań}
Tekst sekcji

\begin{thebibliography}{99}
\addcontentsline{toc}{chapter}{Bibliografia}

\bibitem [Covington(1984)]{Covington1984}
Covington, M.A. (1984). \textit{Syntactic theory in~the high Middle Ages: Modistic models of~sentence structure}
(Cambridge Studies in~Linguistics). Cambridge: Cambridge University Press. %Za: de~Marneffe, M.-C. \& Nivre, J. (2019). Dependency Grammar. \textit{Annual Review of~Linguistics} 5, 197–218. \url{https://doi.org/10.1146/annurev-linguistics-011718-011842}

\bibitem [Futrell et~al.(2015)]{FutrellEtAl2015}
Futrell, R., Mahowald, K., \& Gibson, E. (2015). Large-scale evidence of~dependency length minimization in~37 languages. \textit{Proceedings of~the National Academy of~Sciences} 112(33), 10336–10341. \url{https://doi.org/10.1073/pnas.1502134112}

\bibitem [Futrell et~al.(2020)]{FutrellEtAl2020}
Futrell, R., Levy~R. P., \& Gibson, E. (2020). Dependency locality as~an~explanatory principle for word order. \textit{Language} 96(2), 371–412. %Za: Anonimowe Zgłoszenie na~ACL 2023 (nieopublikowane). Conjunct Lengths in~English, Dependency Length Minimization, and Dependency Structure of~Coordination

\bibitem [Haspelmath(2007)]{Haspelmath2007}
Haspelmath, M. (2007). Coordination. In~T. Shopen (Ed.), \textit{Language typology and syntactic description, Volume II: Complex constructions} (pp. 1–51). Cambridge University Press.

\bibitem [Hawkins(1994)]{Hawkins1994}
Hawkins, J. A. (1994). A~Performance Theory of~Order and Constituency. \textit{Cambridge University Press}. %Za: Anonimowe Zgłoszenie na~ACL 2023 (nieopublikowane). Conjunct Lengths in~English, Dependency Length Minimization, and Dependency Structure of~Coordination

\bibitem [Jing et~al.(2022)]{Jing2022}
Jing, Y., Blasi, D., \& Bickel, B. (2022). Dependency Length Minimization and its limits: A~possible fole for a~probabilistic version of~the Final-Over-Final condition. \textit{Language} 98(3). \url{https://doi.org/10.1353/lan.2022.0013}.

\bibitem [Kruijff(2002)]{Kruijff2002}
Kruijff, G.-J. M. (2002). Formal and computational aspects of~dependency grammar: History and development of~dg. \textit{Technical report}, ESSLI2002. %Za: Pedersen, M., Eades, D. Amin, S. K. \& Prakash, L. (2004). Relative Clauses in~Hindi and Arabic: A~Paninian Dependency Grammar Analysis. In~\textit{Proceedings of~the Workshop on~Recent Advances in~Dependency Grammar} (pp. 9–16). Geneva, COLING

\bibitem [Liu(2008)]{Liu2008}
Liu, H. (2008). Dependency distance as~a~metric of~language comprehension difficulty. \textit{Journal of~Cognitive Science} 9(2), 159–191. \url{https://doi.org/10.17791/jcs.2008.9.2.159}

\bibitem[de Marneffe \& Nivre(2019)]{Marneffe2019}
de~Marneffe, M.-C. \& Nivre, J. (2019). Dependency Grammar. \textit{Annual Review of~Linguistics} 5, 197–218. \url{https://doi.org/10.1146/annurev-linguistics-011718-011842}

\bibitem [Mel'čuk(1988)]{Melcuk1988}
Mel'čuk, I.A. (1988). \textit{Dependency syntax: theory and practice.} SUNY press. %Za: de~Marneffe, M.-C. \& Nivre, J. (2019). Dependency Grammar. \textit{Annual Review of~Linguistics} 5, 197–218. \url{https://doi.org/10.1146/annurev-linguistics-011718-011842}

\bibitem [Przepiórkowski \& Patejuk(2020)]{Przepiorkowski2020}
Przepiórkowski, A., Patejuk, A. (2020). From Lexical Functional Grammar to~enhanced Universal Dependencies. \textit{Lang Resources \& Evaluation} 54, 185–221. \url{https://doi.org/10.1007/s10579-018-9433-z}

\bibitem [Przepiórkowski \& Woźniak(2023)]{Przepiorkowski2023}
Przepiórkowski, A. \& Woźniak, M. (2023). Conjunct lengths in~English, Dependency Length Minimization, and dependency structure of~coordination, [Manuskrypt zgłoszony do publikacji] %Jeśli chcesz zacytować niepublikowany rękopis, podaj dane autorów, rok napisania, tytuł rękopisu z odpowiednim oznaczeniem („Rękopis przesłany do druku”, „Rękopis w przygotowaniu”, „Niepublikowany rękopis”) oraz, jeśli jest dostępne, odpowiednie źródło (np. wydział uczelni).
%Nowak, J. (2020). Fonetyka języka francuskiego w Kamerunie [Manuskrypt został przesłany do publikacji]. Wydział Filologiczny, Uniwersytet w Białymstoku.
%Uwaga: tytułu czasopisma, do którego podano rękopis, nie podaje się w odniesieniu bibliograficznym.
% ~ https://www.grafiati.com/pl/info/apa-7/preprint/ 

\bibitem [Popel et~al.(2013)]{PopelEtAl2013}
Popel, M., Mareček, D., Štěpánek, J., Zeman, D. \& Žabokrtský, Z. (2013). Coordination structures in~dependency treebanks. \textit{Proceedings of~the 51st Annual Meeting of~the Association for Computational Linguistics (Volume 1: Long Papers)}, pp. 517–527. Sofia, Bulgaria

\bibitem [Tesnière(1959)]{Tesniere1959}
Tesnière, L. (1959). \textit{Éléments de~syntaxe structurale.} C. Klincksieck. %Za: de~Marneffe, M.-C. \& Nivre, J. (2019). Dependency Grammar. \textit{Annual Review of~Linguistics} 5, 197-218. \url{https://doi.org/10.1146/annurev-linguistics-011718-011842}

\end{thebibliography}

\chapter*{Załączniki}
\addcontentsline{toc}{chapter}{Załączniki}

A -- link do~plików z~preprocessingiem danych: \url{https://github.com/kvmilos/PracaLicencjacka/tree/master/preprocessing} \\
B -- link do~pliku z~analizą danych: \url{https://github.com/kvmilos/PracaLicencjacka/blob/master/analizy/r.R} \\
C -- link do~tabeli danych po~preprocessingu w~formacie „.csv”: \url{https://github.com/kvmilos/PracaLicencjacka/blob/master/tabela.csv}
\end{document}